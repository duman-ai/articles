<!DOCTYPE html><html lang="fa" dir="rtl"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="google-site-verification" content="uJhk65F5Bbumnlk_5zO5wU_QB3Qd5T2L8hAV07wX_rI"><title>Duman AI Newsletter</title><link rel="icon" type="image/png" href="/_astro/logo.C7PaCSgx.png"><link rel="stylesheet" href="/styles/global.css"><link href="https://fonts.googleapis.com/css2?family=Vazirmatn&display=swap" rel="stylesheet"><style>:root{--bg: #f9fafb;--text: #111827;--accent: #4f46e5;--header-bg: #ffffff;--footer-bg: #f3f4f6;--radius: 16px}body{margin:0;font-family:Vazirmatn,Tahoma,sans-serif;background-color:var(--bg);color:var(--text);direction:rtl;line-height:1.8}header{background-color:var(--header-bg);padding:2rem 1.5rem;box-shadow:0 2px 6px #0000000d;text-align:center}header h1{margin:0;font-size:2rem;color:var(--accent)}main{max-width:800px;margin:2rem auto;padding:0 1.5rem}.post{background:#fff;border-radius:var(--radius);box-shadow:0 2px 10px #0000000a;margin-bottom:2rem;padding:2rem}.post h2{margin-top:0;color:var(--accent);font-size:1.4rem;margin-bottom:1rem}.post p{font-size:1.05rem;text-align:justify}footer{background-color:var(--footer-bg);text-align:center;padding:1rem;font-size:.9rem;color:#6b7280;margin-top:3rem;border-top:1px solid #e5e7eb}@media (max-width: 600px){header h1{font-size:1.5rem}.post{padding:1.5rem}.post h2{font-size:1.2rem}.post p{font-size:1rem}}.robot-slider{direction:rtl;font-family:Vazirmatn,sans-serif;display:flex;justify-content:center;padding:2rem 1rem}.slider-container{max-width:700px;width:100%;background:#fff;border-radius:20px;box-shadow:0 10px 30px #00000014;overflow:hidden;text-align:center}.slide-card{padding:1rem}.slide-card img{width:100%;border-radius:16px;box-shadow:0 4px 16px #0000001a;margin-bottom:1rem;transition:.5s}.slide-text{font-size:1rem;line-height:1.8;padding:0 1rem;text-align:justify}.slide-text a{color:#07c;text-decoration:none;font-weight:700}.slide-counter{margin-top:1rem;font-size:.95rem;color:#666}.slider-controls{display:flex;justify-content:space-between;padding:1rem}.slider-controls button{background:#07c;color:#fff;border:none;border-radius:12px;padding:.6rem 1.2rem;font-size:1rem;cursor:pointer;transition:.3s}.slider-controls button:hover{background:#005fa3}@media (max-width: 600px){.slide-text{font-size:.95rem}.slider-controls button{font-size:.9rem;padding:.5rem 1rem}}.post-meta{margin-top:10px;font-size:.9rem;color:#666;display:flex;flex-direction:column;gap:4px}.post-meta-index{margin:8px 0;font-size:.85rem;color:#555;display:flex;flex-direction:row;gap:1rem;flex-wrap:wrap}
</style></head> <body>  </body></html> <header> <div class="flex justify-center w-full py-4"> <a href="/" class="cursor-pointer"> <img src="/_astro/logo.C7PaCSgx.png" alt="خبرنامه هوش‌مصنوعی دومان" class="header-logo-image"> </a> </div> <h1>پرامپت و تکنیک‌های آن</h1> <div class="post-meta"> <span>🗓️ تاریخ انتشار: ۱۱ می ۲۰۲۵</span> <span>✍️ نویسنده: <a href="https://pouyae.xyz" target="_blank">Pouya Esmaeili</a></span> </div> </header> <main> <div class="post"> <p>
پرامپت (Prompt) ورودی مدل‌ زبانی است که برای رسیدن به پاسخ مورد نظر نوشته می‌شود. یک پرامپت از
      اجزای مختلفی ساخته شده که مشخص کردن آن‌ها کاربر را برای رسیدن به پاسخ بهتر در زمان کم کمک ‌می‌کند.
      الزاماً تمامی این اجزا در یک پرامپت وجود ندارد. در ادامه هر کدام از این اجزا با مثالی که در تصویر زیر
      نمایش داده شده معرفی می‌شود. برای استفاده صحیح از مدل‌های زبانی صرفاً نوشتن پرامپت کافی نیست. بلکه باید
      پارامترهای مهم در پیکربندی مدل را نیز بشناسید. برای آشنایی بیشتر با این پارامترها <a href="llm-inference-configuration.html">اینجا</a> را
      بخوانید.
</p> <div style="display: flex; flex-direction: column; align-items: center; margin-bottom: 20px;"> <img src="https://i.postimg.cc/XYkw4rwF/prompt-example.jpg" alt="مثال بررسی پرامپت و اجزای آن" style="max-width: 65%; height: auto;"> <p style="font-size: 14px; color: #555; margin-top: 8px;">مثال بررسی پرامپت و اجزای آن</p> </div> <h4 dir="ltr" style="font-weight: bold;">Instruction:</h4> <p>دستوراتی که می‌خواهیم اجرا شود. در اینجا سورت کردن از بیشترین به کمترین و محاسبه بازدهی به درصد دستورات پرامپت هستند.</p> <h4 dir="ltr" style="font-weight: bold;">Context:</h4> <p>اطلاعاتی که به مشخص شدن حوزه مورد درخواست کمک کرده و یا آن را محدودتر می‌کند. در اینجا عبارت "در این جدل قیمت خرید و فروش سهام مشخص شده است." موضوع را مشخص می‌کند.</p> <h4 dir="ltr" style="font-weight: bold;">Input Data:</h4> <p>اطلاعاتی که به عنوان ورودی نیاز است. در اینجا محتوای فایل CSV دیتای ورودی مورد نیاز مدل است.</p> <h4 dir="ltr" style="font-weight: bold;">Output Indicator:</h4> <p>شکل یا فرمت پاسخی که انتظار داریم را مشخص کنیم. در اینجا عبارات به صورت جدول و بدون توضیحات و کد شکل خروجی مورد انتظار را مشخص می‌کند.</p> <div style="display: flex; flex-direction: column; align-items: center; margin-bottom: 20px;"> <img src="https://i.postimg.cc/X7w5kr1h/prompt-structure.webp" alt="اجزای پرامپت" style="max-width: 75%; height: auto;"> <p style="font-size: 14px; color: #555; margin-top: 8px;">اجزای پرامپت</p> </div> <p>در ادامه رایج‌ترین تکنیک‌های پرامپت‌نویسی معرفی می‌شود.</p> <h3 dir="ltr">1. ZeroShot Prompting (General Prompting):</h3> <p>این تکنیک ساده‌ترین روش پرامپت نویسی است. در این روش کاربر سوال خود را در یک پیام از مدل زبانی می‌پرسد. با توسعه مدل‌های زبانی توانایی آن برای پاسخ دادن به گستره‌ای بزرگ و متنوع از حوزه‌ها افزایش پیدا کرده و این روش ساده به راحتی قابل استفاده خواهد بود. اگر روش  ZeroShot کاربر را به پاسخ نرساند تکنیک‌های پیشرفته‌تر مورد استفاده قرار می‌گیرد.</p> <h3 dir="ltr">2. FewShot Prompting:</h3> <p>در این تکنیک کاربر چند مثال برای مدل فراهم می‌کند تا آن را برای رسیدن به الگو و پاسخ مورد نظر خود هدایت کند. تفاوت روش FewShot و ZeroShot در تعداد مثال‌هاست. روش FewShot برای سوالات پیچیده‌تر به کار می‌رود. فراهم کردن مثال‌های متعدد مدل را برای یادگیری روش پاسخگویی به یک تسک/سوال هدایت می‌کند که به آن In-context learning (ICL) گفته می‌شود. </p> <h3 dir="ltr">3. Chain of Thoughts (CoT):</h3> <p>در این روش مدل زبانی برای تولید قدم‌های میانی در استنتاج و محاسبات هدایت می‌شود. به عبارت دیگر مدل قدم به قدم روش محاسبه خود را شرح داده و طبق آن پیش می‌رود. این تکنیک به تولید پاسخ دقیق در تسک‌های ریاضیاتی و استنتاجی کمک می‌کند. معمولاً تکنیک Chain of Thoughts به همراه FewShot Prompting  به‌کار می‌رود. در تصویر زیر نتیجه روش Chain of Thoughts در مقایسه با ZeroShot Prompting مقایسه شده است. معمولاً برای هدایت مدل با تکنیک Chain of Thoughts باید حداقل یک مثال به آن ارائه شده و از آن درخواست شود مشابه مثال قدم به قدم (Step by Step) پاسخ دهد. </p> <div style="display: flex; flex-direction: column; align-items: center; margin-bottom: 20px;"> <img src="https://i.postimg.cc/NjBHJQW0/cot-example.png" alt="مقایسه Chain of Thoughts و ZeroShot" style="max-width: 75%; height: auto;"> <p style="font-size: 14px; color: #555; margin-top: 8px;">مقایسه Chain of Thoughts و ZeroShot</p> </div> <p>نسخه جامع‌تر Chain of Thoughts (CoT) روش Tree of Thoughts (ToT) نام دارد. در ToT به جای یک مسیر مستقیم از استنتاج مسیرهای پیچیده‌تری از استنتاج طی می‌شود. برای مقایسه CoT و ToT تصویر زیر را مشاهده کنید. </p> <div style="display: flex; flex-direction: column; align-items: center; margin-bottom: 20px;"> <img src="https://i.postimg.cc/s20Gg71B/tot-cot.png" alt="مقایسه ToTو CoT" style="max-width: 75%; height: auto;"> <p style="font-size: 14px; color: #555; margin-top: 8px;">مقایسه ToTو CoT</p> </div> <h3 dir="ltr">4. ReAct (Reasoning and Action):</h3> <p>این روش از سرویس‌ها و ابزارهای خارجی در تسک‌های پیچیده نظیر برنامه‌نویسی فیدبک می‌گیرد. روش ReAct از رفتار انسان تقلید کرده و در ایجنت‌های مبتنی بر LLM بسیار مورد استفاده قرار می‌گیرد. به عنوان مثال در نظر بگیرید می‌خواهید با LLM برای یک مساله برنامه بنویسید. بعد از تولید کد آن را اجرا کرده و خطای آن را دوباره به مدل می‌دهید و از آن می‌خواهید که این خطا را تصحیح کند. این چرخه تا رسیدن به پاسخ صحیح ادامه پیدا می‌کند. این چرخه شامل قدم‌های متوالی Reasoning و Action است. در Reasoning مدل پاسخ پیشنهادی را تولید کرده و در Action نتیجه پاسخ قبلی در ابزارها (محیط برنامه‌نویسی، موتور جستجو و یا APIهای سرویس خارجی) اجرا می‌شود. اگر کاربر به پاسخ خود رسیده باشد چرخه قطع شده و در غیر این صورت از نتایج Action برای Reasoning جدید استفاده می‌شود. این چرخه در تصویر زیر نمایش داده شده است. </p> <div style="display: flex; flex-direction: column; align-items: center; margin-bottom: 20px;"> <img src="https://i.postimg.cc/h4mQKJnj/react.png" alt="فلوی ReAct" style="max-width: 75%; height: auto;"> <p style="font-size: 14px; color: #555; margin-top: 8px;">فلوی ReAct</p> </div> <h3 dir="ltr">5. Self-Consistency:</h3> <p>در این روش با استفاده از CoT مسیرهای مختلف استنتاج توسط مدل پیشنهاد شده و در نهایت کاربر مناسب‌ترین مسیر را انتخاب می‌کند. در واقع روش Self-Consistency عملکرد تکنیک CoT را تقویت می‌کند، در عین حال هزینه استفاده از مدل نیز بالاتر می‌رود زیرا به جای یک پاسخ چند پاسخ تولید شده است. </p> <h3 dir="ltr">6. Meta Prompting:</h3> <p>در این روش از مدل زبانی (ترجیحاً مدل‌های قدرتمندتر) برای ساختن پرامپت یا بهینه کردن یک پرامپت استفاده می‌شود. شما می‌توانید از یک مدل زبانی بخواهید پرامپت شما را ویرایش کند یا آن را برای کاهش هزینه (براساس سایز توکن ورودی و خروجی) بهینه کند. حتی می‌توانید با فراهم جزئیات از یک مدل بخواهید که برای شما پرامپت مناسب را تولید کند. </p> <h3 dir="ltr">7. System/ Role prompting:</h3> <p>معمولاً در مدل‌هایی زبانی تصویر کلی آن چیزی که از مدل انتظار در قالب System Prompt یا Instructions مشخص می‌شود.</p> <p>مثال از فرمت خروجی: همیشه در این ساختار Json Schema پاسخ بده …</p> <p>مثال از آموزش زبان انگلیسی: فرض کن معلم زبان انگلیسی هستی و در حال یاد دادن زبان به کاربر فارسی زبان هستی.</p> <p>همان‌طور که در مثال قبلی مشاهده کردید، یکی از راه‌های هدایت مدل به سمت نیاز کاربر مشخص کردن نقش (Role) آن است. به همین جهت زمانی که در پرامپت از مدل می‌خواهیم در نقش مورد نظر ما ظاهر شود به آن <strong>Role Prompting</strong> گفته می‌شود.</p> <h3>مطالعه بیشتر در:</h3> <ul dir="ltr"> <li><a href="https://tonylixu.medium.com/langchain-prompt-template-0359d96090c5" target="_blank">LangChain — Prompt Template. What is a Prompt</a></li> <li><a href="https://www.kaggle.com/whitepaper-prompt-engineering" target="_blank">Prompt Engineering by Google</a></li> <li><a href="https://www.promptingguide.ai/" target="_blank">Prompt Engineering Guide</a></li> <li><a href="https://cobusgreyling.medium.com/react-synergy-between-reasoning-acting-in-llms-36fc050ae8c7" target="_blank">ReAct: Synergy Between Reasoning & Acting In LLMs | by Cobus Greyling</a></li> </ul> </div> </main> <footer style="background-color: #f8f9fa; text-align: center; padding: 20px; font-family: sans-serif; font-size: 14px; color: #333; border-top: 1px solid #ddd;"> <p style="margin: 8px 0;">&copy; 2025 خبرنامه هوش‌مصنوعی دومان. تمامی حقوق محفوظ است.</p> <p style="margin: 8px 0;">انتشار مطالب تنها با ذکر منبع مجاز است.</p> <p style="margin: 8px 0;">
کانال تلگرام:
<a href="https://t.me/dumannewsletter" target="_blank" style="color: #0077b6; text-decoration: none;">
@dumannewsletter
</a> </p> </footer>